import json
import random
import numpy as np
import re
from collections import Counter

# generated by chatgpt 4o
wdc_synonym_map = {
    # Automotive
    "Motorcycle": ["Bike", "Motorbike"],
    "Handlebar": ["Steering Bar", "Grip Bar"],
    "Mount": ["Bracket", "Holder"],
    "Base": ["Platform", "Foundation"],
    "Charging": ["Power", "Energy"],
    "Hub": ["Station", "Dock"],
    "Battery": ["Power Cell", "Energy Unit"],
    "Camera": ["Imaging Unit", "Lens System"],
    "Gimbal": ["Stabilizer", "Pivot"],
    "Autel": ["Autel Robotics", "Autel Brand"],
    "Evo": ["EVO 2", "EVO II Series"],
    "U-Bolt": ["U Clamp", "U Fastener"],
    "Triple": ["3-Way", "Three-Point"],
    "Ball": ["Joint", "Knob"],

    # Camera and Photo
    "Lens": ["Optic", "Glass"],
    "Zoom": ["Magnification", "Extension"],
    "Film": ["Photo Sheet", "Photographic Media"],
    "Macro": ["Close-Up", "Detail"],
    "Telephoto": ["Long Range", "Distance"],
    "Mirrorless": ["No Mirror", "Digital Frame"],
    "Tripod": ["Stand", "Stabilizer"],
    "Grip": ["Handle", "Hold"],
    "Paper": ["Print Sheet", "Media"],

    # Cell Phones and Accessories
    "Iphone": ["iPhone", "Apple Phone"],
    "Charger": ["Power Adapter", "Charging Unit"],
    "Cable": ["Cord", "Wire"],
    "Adapter": ["Converter", "Connector"],
    "Magsafe": ["Magnetic Safe", "Magsafe Power"],
    "Lightning": ["Flash Connector", "Light Cable"],
    "Usb-C": ["USB Type-C", "C-Type"],
    "Screen": ["Display", "Touchscreen"],
    "Fix": ["Repair", "Restore"],
    "Kit": ["Set", "Package"],
    "Replacement": ["Spare", "Alternate"],
    "New": ["Fresh", "Brand New"],
    "Flash": ["Quick", "Rapid"],

    # Clothing
    "Cap": ["Hat", "Headwear"],
    "Baseball": ["Ball Game", "Diamond Sport"],
    "Sunglasses": ["Shades", "Eyewear"],
    "Unisex": ["Gender Neutral", "All-Gender"],
    "White": ["Light", "Ivory"],
    "Navy": ["Blue", "Midnight"],
    "Red": ["Crimson", "Scarlet"],
    "Green": ["Olive", "Lime"],
    "Gradient": ["Fade", "Ombre"],
    "Classic": ["Traditional", "Vintage"],
    "Fullcap": ["Fitted Cap", "Snug Hat"],
    "Strapback": ["Adjustable Cap", "Buckle Back"],

    # Home and Garden
    "Oven": ["Stove", "Baking Unit"],
    "Freezer": ["Cooling Unit", "Icebox"],
    "Dryer": ["Tumbler", "Heater"],
    "Washing": ["Laundry", "Cleaning"],
    "Grill": ["Barbecue", "Roaster"],
    "Cooktop": ["Hob", "Stove Top"],
    "Gas": ["Fuel", "Combustion"],
    "Electric": ["Powered", "Electro"],
    "Fridge": ["Refrigerator", "Cooler"],
    "Charcoal": ["Coal", "Carbon"],
    "Steel": ["Metal", "Alloy"],

    # Jewelry
    "Watch": ["Timepiece", "Wristwatch"],
    "Strap": ["Band", "Bracelet"],
    "Stainless": ["Steel", "Inox"],
    "Chronograph": ["Chrono", "Stopwatch"],
    "Dial": ["Face", "Display"],
    "Automatic": ["Self-Winding", "Auto"],
    "Quartz": ["Battery", "Electronic"],
    "Leather": ["Hide", "Skin"],
    "Bracelet": ["Chain", "Link"],
    "Men's": ["Gents", "Male"],
    "Women's": ["Ladies", "Female"],
    "Replica": ["Imitation", "Copy"],
    "Gold": ["Aurum", "Gilded"],

    # Movies and TV
    "TV": ["Television", "Display"],
    "LED": ["Light Emitting Diode", "LED Backlit"],
    "OLED": ["Organic LED", "OLED Panel"],
    "QLED": ["Quantum LED", "Q-Display"],
    "HDR": ["High Dynamic Range", "HDR10"],
    "Smart": ["Connected", "Intelligent"],
    "Ultra": ["Super", "Extreme"],
    "HD": ["High Definition", "1080p"],
    "4K": ["UHD", "UltraHD"],
    "Class": ["Model", "Series"],
    "Inch": ["\"", "In."],
    "WiFi": ["Wireless", "WLAN"],

    # Musical Instruments
    "Guitar": ["Electric Guitar", "Six-String"],
    "Strings": ["Wires", "Strands"],
    "Bass": ["Low-End", "Deep Tone"],
    "Mandolin": ["Miniature Lute", "Eight-String"],
    "Drum": ["Percussion", "Beatmaker"],
    "Head": ["Skin", "Surface"],
    "Microphone": ["Mic", "Sound Pickup"],
    "Acoustic": ["Unplugged", "Hollow Body"],
    "Wound": ["Wrapped", "Coiled"],
    "Nickel": ["Metal", "Alloy"],
    "Bronze": ["Copper Alloy", "Gold-Tone"],

    # Tools and Home Improvement
    "Tool": ["Instrument", "Device"],
    "Wrench": ["Spanner", "Tightener"],
    "Drill": ["Borer", "Perforator"],
    "Hammer": ["Mallet", "Pounder"],
    "Compact": ["Mini", "Small"],
    "Breaker": ["Splitter", "Separator"],
    "Bracket": ["Mount", "Support"],
    "Light": ["Lamp", "Luminaire"],
    "Chain": ["Link", "Loop"],
    "Bottom": ["Lower", "Base"],

    # Computers and Accessories
    "Asus": ["ASUS", "AsusTek"],
    "Radeon": ["AMD Radeon", "Graphics Card"],
    "Geforce": ["NVIDIA GeForce", "GPU"],
    "SSD": ["Solid State Drive", "Flash Drive"],
    "HDD": ["Hard Disk Drive", "Mechanical Drive"],
    "RAM": ["Memory", "DRAM"],
    "DDR4": ["DDR-4", "DR4"],
    "USB": ["Universal Serial Bus", "U.S.B."],
    "MicroSD": ["Micro SD", "TF Card"],
    "Motherboard": ["Mainboard", "Logic Board"],
    "Monitor": ["Display", "Screen"],
    "Laptop": ["Notebook", "Portable Computer"],
    "Intel": ["IntelÂ®", "Processor Brand"],
    "Core": ["CPU", "Processor"],
    "Silver": ["Chrome", "Metallic"],
    "Kingston": ["Kingston Technology", "Kingston Inc."],
    "SanDisk": ["Sandisk", "SANDISK"],

    # Office Products
    "Toner": ["Powder Ink", "Print Powder"],
    "Cartridge": ["Cart", "Ink Unit"],
    "Magenta": ["Pink", "Red Violet"],
    "Cyan": ["Blue-Green", "Aqua"],
    "Yellow": ["Gold", "Lemon"],
    "High": ["Elevated", "Enhanced"],
    "Yield": ["Output", "Capacity"],
    "Original": ["OEM", "Genuine"],
    "Compatible": ["Alt", "Replacement"],
    "Multipack": ["Bundle", "Combo Pack"],
    "Printer": ["Print Device", "Print Machine"],
    "Laser": ["Toner-Based", "Beam Print"],
    "XL": ["Extra Large", "Extended"],
    "Pack": ["Set", "Bundle"],
    "Refill": ["Recharge", "Reload"],
    "Matte": ["Flat", "Non-Glossy"],
    "Photo": ["Image", "Picture"],
    "Maintenance": ["Service", "Upkeep"],
    "Ribbon": ["Strip", "Tape"],
    "Grey": ["Gray", "Ash"],
    "Light": ["Pale", "Faint"],
    "Ultra": ["Extreme", "High-End"],

    # Other Electronics
    "Router": ["Gateway", "Access Router"],
    "Switch": ["Hub", "Network Switch"],
    "Gigabit": ["1000Mbps", "Giga Ethernet"],
    "Access": ["Entry", "Inbound"],
    "Point": ["Node", "Terminal"],
    "PoE": ["Power over Ethernet", "Inline Power"],
    "Port": ["Slot", "Connector"],
    "Channel": ["CH", "Input Line"],
    "UPS": ["Battery Backup", "Power Backup"],
    "Mono": ["Single Ear", "Monoaural"],
    "Stereo": ["Dual Ear", "Binaural"],
    "Extender": ["Repeater", "Booster"],
    "Range": ["Distance", "Coverage"],
    "Ethernet": ["LAN", "Network"],
    "Ceiling": ["Overhead", "Top Mount"],
    "Rack": ["Mountable", "Cabinet"],
    "Tower": ["Vertical", "Standalone"],
    "Outdoor": ["External", "Weatherproof"],
    "DVR": ["Recorder", "Video Recorder"],
    "NVR": ["Network Recorder", "Digital Recorder"],
    "Transducer": ["Sensor", "Converter"],
    "Antenna": ["Aerial", "Transmitter"],
    "Module": ["Unit", "Component"],
    "Jack": ["Port", "Socket"],

    # Sports and Outdoors
    "Tire": ["Tyre", "Rubber"],
    "Tube": ["Inner Tube", "Air Tube"],
    "Pedal": ["Foot Lever", "Step Plate"],
    "Cleat": ["Shoe Plate", "Foot Clip"],
    "Chain": ["Link Drive", "Bike Chain"],
    "Cassette": ["Gear Cluster", "Cogset"],
    "Derailleur": ["Shifter", "Gear Mech"],
    "Shifter": ["Gear Lever", "Changer"],
    "Crank": ["Crank Arm", "Pedal Arm"],
    "Bracket": ["Mount", "Base"],
    "SPD": ["Shimano Pedal Design", "Clipless"],
    "SL": ["Sport Level", "SL-Type"],
    "Watch": ["Timepiece", "Wearable"],
    "GPS": ["Tracker", "Navigation"],
    "Mount": ["Holder", "Adapter"],
    "Speed": ["Gear", "Ratio"],
    "Trigger": ["Activator", "Lever"],
    "Rear": ["Back", "Behind"],
    "Front": ["Head", "Lead"],
    "Black": ["Jet", "Dark"],
    "Silver": ["Chrome", "Steel"],
    "Yellow": ["Lemon", "Bright"],
    "Red": ["Crimson", "Scarlet"],
    "Ball": ["Knob", "Pivot"]
}

domain_synonym_maps = {
    "wdc": wdc_synonym_map,
}

def get_synonym_map(domain):
    # search for the right synonym map
    for k in list(domain_synonym_maps.keys()):
        print(f"SYNONYM MAP: {k}")
        if k in domain:
            return domain_synonym_maps[k]
    print(f"SYNONYM MAP: NONE")
    return None

# expect ditto format for data
# TODO: TEST THIS FUNCTION IN THE PIPELINE
def augment_entity_matching_dataset(
    data: list,
    domain: str,
    target_total: int,
    include_original: bool = True
):
    # determine the synonym map
    synonym_map = get_synonym_map(domain)
    
    # parse pairs and labels
    pairs = []
    titles = set()
    for line in data[domain][0]:
        parts = line.strip().split("\t")
        if len(parts) == 3:
            title1 = re.search(r'COL title VAL  "(.*?)"@\w+', parts[0]).group(1)
            title2 = re.search(r'COL title VAL  "(.*?)"@\w+', parts[1]).group(1)
            label = parts[2]
            pairs.append(((title1, title2), label))
            titles.add(title1)
            titles.add(title2)

    total_existing = len(pairs)

    # get the needed number of samples to fill the budget target total
    needed_total = target_total - total_existing
    label_counts = Counter([label for _, label in pairs])
    existing_pos = label_counts["1"]
    existing_neg = label_counts["0"]
    pos_ratio = existing_pos / total_existing
    target_pos = int(target_total * pos_ratio)
    target_neg = target_total - target_pos
    needed_pos = (target_pos - existing_pos)# // 2
    needed_neg = (target_neg - existing_neg)# // 2

    # paraphrasing function
    def local_paraphrase(title):
        words = title.split()
        new_words = []
        for word in words:
            base = word.strip('.,:-_()"')
            if base in synonym_map:
                synonym = random.choice(synonym_map[base])
                new_words.append(synonym)
            else:
                new_words.append(word)
        return ' '.join(new_words)

    # generate positive samples
    new_pos = []
    pos_pairs = [(t1, t2) for (t1, t2), label in pairs if label == "1"]
    existing_pair_set = set((t1, t2) for (t1, t2), _ in pairs)
    existing_pair_set |= set((t2, t1) for (t1, t2), _ in pairs)
    while len(new_pos) < needed_pos:
        t1, t2 = random.choice(pos_pairs)
        if random.random() > 0.5:
            t1 = local_paraphrase(t1)
        else:
            t2 = local_paraphrase(t2)
        new_pos.append(f'COL title VAL  "{t1}"@en\tCOL title VAL  "{t2}"@en\t1\n')

    # generate negative samples
    titles_list = list(titles)
    new_neg = []
    while len(new_neg) < needed_neg:
        t1, t2 = random.sample(titles_list, 2)
        if (t1, t2) not in existing_pair_set:
            new_neg.append(f'COL title VAL  "{t1}"@en\tCOL title VAL  "{t2}"@en\t0\n')
            existing_pair_set.add((t1, t2))
        else:
            new_neg.append(f'COL title VAL  "{t2}"@en\tCOL title VAL  "{t1}"@en\t0\n')
            existing_pair_set.add((t2, t1))


    # collect output
    if include_original:
        result = data[domain][0] + new_pos + new_neg
    else:
        result = new_pos + new_neg
    
    # return the augmented data as a list of strings
    return result


# ditto augmenter
class Augmenter(object):
    """Data augmentation operator.

    Support both span and attribute level augmentation operators.
    """
    def __init__(self):
        pass

    def augment(self, tokens, labels, op='del'):
        """ Performs data augmentation on a sequence of tokens

        The supported ops:
           ['del', 'drop_col',
            'append_col', 'drop_token',
            'drop_len',
            'drop_sym',
            'drop_same',
            'swap',
            'ins',
            'all']

        Args:
            tokens (list of strings): the input tokens
            labels (list of strings): the labels of the tokens
            op (str, optional): a string encoding of the operator to be applied

        Returns:
            list of strings: the augmented tokens
            list of strings: the augmented labels
        """
        if 'del' in op:
            # insert padding to keep the length consistent
            # span_len = random.randint(1, 3)
            span_len = random.randint(1, 2)
            pos1, pos2 = self.sample_span(tokens, labels, span_len=span_len)
            if pos1 < 0:
                return tokens, labels
            new_tokens = tokens[:pos1] + tokens[pos2+1:]
            new_labels = tokens[:pos1] + labels[pos2+1:]
        elif 'swap' in op:
            span_len = random.randint(2, 4)
            pos1, pos2 = self.sample_span(tokens, labels, span_len=span_len)
            if pos1 < 0:
                return tokens, labels
            sub_arr = tokens[pos1:pos2+1]
            random.shuffle(sub_arr)
            new_tokens = tokens[:pos1] + sub_arr + tokens[pos2+1:]
            new_labels = tokens[:pos1] + ['O'] * (pos2 - pos1 + 1) + labels[pos2+1:]
        elif 'drop_len' in op:
            # drop tokens below a certain length
            all_lens = [len(token) for token, label in \
                    zip(tokens, labels) if label == 'O']
            if len(all_lens) == 0:
                return tokens, labels
            target_lens = random.choices(all_lens, k=1)
            new_tokens = []
            new_labels = []

            for token, label in zip(tokens, labels):
                if label != 'O' or len(token) not in target_lens:
                    new_tokens.append(token)
                    new_labels.append(label)
            return new_tokens, new_labels
        elif 'drop_sym' in op:
            def drop_sym(token):
                return ''.join([ch if ch.isalnum() else ' ' for ch in token])
            dropped_tokens = [drop_sym(token) for token in tokens]
            new_tokens = []
            new_labels = []
            for token, d_token, label in zip(tokens, dropped_tokens, labels):
                if random.randint(0, 4) != 0 or label != 'O':
                    new_tokens.append(token)
                    new_labels.append(label)
                else:
                    if d_token != '':
                        new_tokens.append(d_token)
                        new_labels.append(label)
        elif 'drop_same' in op:
            left_token = set([])
            right_token = set([])
            left = True
            for token, label in zip(tokens, labels):
                if label == 'O':
                    token = token.lower()
                    if left:
                        left_token.add(token)
                    else:
                        right_token.add(token)
                if token == '[SEP]':
                    left = False

            same = left_token & right_token
            targets = random.choices(list(same), k=1)
            new_tokens, new_labels = [], []
            for token, label in zip(tokens, labels):
                if token.lower() not in targets or label != 'O':
                    new_tokens.append(token)
                    new_labels.append(label)
            return new_tokens, new_labels
        elif 'drop_token' in op:
            new_tokens, new_labels = [], []
            for token, label in zip(tokens, labels):
                if label != 'O' or random.randint(0, 4) != 0:
                    new_tokens.append(token)
                    new_labels.append(label)
            return new_tokens, new_labels
        elif 'ins' in op:
            pos = self.sample_position(tokens, labels)
            symbol = random.choice('-*.,#&')
            new_tokens = tokens[:pos] + [symbol] + tokens[pos:]
            new_labels = labels[:pos] + ['O'] + labels[pos:]
            return new_tokens, new_labels
        elif 'append_col' in op:
            col_starts = [i for i in range(len(tokens)) if tokens[i] == 'COL']
            col_ends = [0] * len(col_starts)
            col_lens = [0] * len(col_starts)
            for i, pos in enumerate(col_starts):
                if i == len(col_starts) - 1:
                    col_lens[i] = len(tokens) - pos
                    col_ends[i] = len(tokens) - 1
                else:
                    col_lens[i] = col_starts[i + 1] - pos
                    col_ends[i] = col_starts[i + 1] - 1

                if tokens[col_ends[i]] == '[SEP]':
                    col_ends[i] -= 1
                    col_lens[i] -= 1
                    break
            candidates = [i for i, le in enumerate(col_lens) if le > 0]
            if len(candidates) >= 2:
                idx1, idx2 = random.sample(candidates,k=2)
                start1, end1 = col_starts[idx1], col_ends[idx1]
                sub_tokens = tokens[start1:end1+1]
                sub_labels = labels[start1:end1+1]
                val_pos = 0
                for i, token in enumerate(sub_tokens):
                    if token == 'VAL':
                        val_pos = i + 1
                        break
                sub_tokens = sub_tokens[val_pos:]
                sub_labels = sub_labels[val_pos:]

                end2 = col_ends[idx2]
                new_tokens = []
                new_labels = []
                for i in range(len(tokens)):
                    if start1 <= i <= end1:
                        continue
                    new_tokens.append(tokens[i])
                    new_labels.append(labels[i])
                    if i == end2:
                        new_tokens += sub_tokens
                        new_labels += sub_labels
                return new_tokens, new_labels
            else:
                new_tokens, new_labels = tokens, labels
        elif 'drop_col' in op:
            col_starts = [i for i in range(len(tokens)) if tokens[i] == 'COL']
            col_ends = [0] * len(col_starts)
            col_lens = [0] * len(col_starts)
            for i, pos in enumerate(col_starts):
                if i == len(col_starts) - 1:
                    col_lens[i] = len(tokens) - pos
                    col_ends[i] = len(tokens) - 1
                else:
                    col_lens[i] = col_starts[i + 1] - pos
                    col_ends[i] = col_starts[i + 1] - 1

                if tokens[col_ends[i]] == '[SEP]':
                    col_ends[i] -= 1
                    col_lens[i] -= 1
            candidates = [i for i, le in enumerate(col_lens) if le <= 8]
            if len(candidates) > 0:
                idx = random.choice(candidates)
                start, end = col_starts[idx], col_ends[idx]
                new_tokens = tokens[:start] + tokens[end+1:]
                new_labels = labels[:start] + labels[end+1:]
            else:
                new_tokens, new_labels = tokens, labels
        else:
            new_tokens, new_labels = tokens, labels

        return new_tokens, new_labels


    def augment_sent(self, text, op='all'):
        """ Performs data augmentation on a classification example.

        Similar to augment(tokens, labels) but works for sentences
        or sentence-pairs.

        Args:
            text (str): the input sentence
            op (str, optional): a string encoding of the operator to be applied

        Returns:
            str: the augmented sentence
        """
        # 50% of chance of flipping
        if ' [SEP] ' in text and random.randint(0, 1) == 0:
            left, right = text.split(' [SEP] ')
            text = right + ' [SEP] ' + left

        # tokenize the sentence
        current = ''
        tokens = text.split(' ')

        # avoid the special tokens
        labels = []
        for token in tokens:
            if token in ['COL', 'VAL']:
                labels.append('HD')
            elif token in ['[CLS]', '[SEP]']:
                labels.append('<SEP>')
            else:
                labels.append('O')

        if op == 'all':
            # RandAugment: https://arxiv.org/pdf/1909.13719.pdf
            N = 3
            ops = ['del', 'swap', 'drop_col', 'append_col']
            for op in random.choices(ops, k=N):
                tokens, labels = self.augment(tokens, labels, op=op)
        else:
            tokens, labels = self.augment(tokens, labels, op=op)
        results = ' '.join(tokens)
        return results

    def sample_span(self, tokens, labels, span_len=3):
        candidates = []
        for idx, token in enumerate(tokens):
            if idx + span_len - 1 < len(labels) and ''.join(labels[idx:idx+span_len]) == 'O'*span_len:
                candidates.append((idx, idx+span_len-1))
        if len(candidates) <= 0:
            return -1, -1
        return random.choice(candidates)

    def sample_position(self, tokens, labels, tfidf=False):
        candidates = []
        for idx, token in enumerate(tokens):
            if labels[idx] == 'O':
                candidates.append(idx)
        if len(candidates) <= 0:
            return -1
        return random.choice(candidates)


if __name__ == '__main__':
    ag = Augmenter()
    text = 'COL content VAL vldb conference papers 2020-01-01 COL year VAL 2020 [SEP] COL content VAL sigmod conference 2010 papers 2019-12-31 COL year VAL 2019'
    for op in ['del',
               'drop_col',
               'append_col',
               'drop_token',
               'drop_len',
               'drop_sym',
               'drop_same',
               'swap',
               'ins',
               'all']:
        print(op)
        print(ag.augment_sent(text, op=op))
